{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "\n",
    "In this notebook, we will perform a clustering task over a simplified version of the [TrackML](https://www.kaggle.com/c/trackml-particle-identification) dataset, wherein each sample is reduced from $\\approx10^5$ points to only $\\approx 10^2$ points. TrackML's goal is to reconstruct the trajectory of particles created when proton bunches accelerated to near the speed of light collide. To capture the particles' paths, the particles pass through many layers of a detector (e.g., Atlas), resulting in a point cloud. Successfully clustering this point cloud such that each cluster is associated to one particle is sufficient for physicists to then extract the particles' trajectories and thus discover their kinematic properties.\n",
    "\n",
    "This notebook presents a simple algorithm that uses a GNN to learn a good embedding for classical clustering algorithm like DBSCAN. While end-to-end and hierarchical clustering is highly desirable, it presents additional challenges which go beyond the scope of this tutorial's purpose in featuring DGL. Interested readers may check out the algorithm introduced in [End-to-End Hierarchical Clustering with Graph Neural Networks](https://cs.nyu.edu/media/publications/choma_nicholas.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "\n",
    "Graph Neural Networks are an attractive candidate since they are capable of aggregating information over variable-sized neighborhoods of points; there is no limitation of modeling just singular or pairwise interactions. Because we begin only with a point cloud, our pipeline will be as follows:\n",
    "\n",
    "1. **Metric learning:** Embed the points into a Euclidean space using an MLP on each point indivually. Points belonging to the same particle should be close; points belonging to different particles should be far. *(provided as input data)*\n",
    "1. **Graph Construction:** Find each point's nearest neighbors in the embedded space, and connect them with a graph. Ensure neighborhoods are large enough to connect most of the points belonging to the same particle. *(provided as input data)*\n",
    "1. **GNN:** Embed the points into another Euclidean space, this time incorporating neighborhood information. Because each point is aware of its neighbors, the GNN produces a superior embedding to the metric learning stage.\n",
    "1. **Clustering:** Using the GNN's embedding, cluster the points with DBSCAN. Adjust DBSCAN's hyperparameters until the TrackML score is maximized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data\n",
    "\n",
    "The dataset consists of detection *events*, wherein a variable number of particles come into contact with the detector's cells. The location of these impacts are called *hits*, and there are likewise a variable number of them per particle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 samples.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "with open('tracks.pickle', 'rb') as f:\n",
    "    samples = pickle.load(f)\n",
    "\n",
    "print(\"Loaded {} samples.\".format(len(samples)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features\n",
    "\n",
    "#### Hits\n",
    "Each sample contains a set of hits, and each hit contains the following information:\n",
    "\n",
    "* *x,y,z* coordinates\n",
    "* Cell count and impact magnitude\n",
    "* A learned hit embedding, output from the previous graph creation stage\n",
    "* Ground truth cluster ID, denoting the particle which created the hit\n",
    "\n",
    "#### Graphs\n",
    "Additionally, samples contain graphs as output from the previous stage which aims to connect hits created by the same particle. The two graphs included are\n",
    "\n",
    "* A predicted graph, the raw output from the graph building stage\n",
    "\n",
    " - print(type(samples[0]))\n",
    "\n",
    "* An augmented graph, which contains the predicted graph, plus any connections missed between hits created by the same particle (positive pairs). One could also add some negative pairs to the graph. This is used in the GNN's loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['hits', 'graphs', 'hier'])\n",
      "Hit Key:dict_keys(['xyz', 'cell', 'emb', 'particle_id', 'weight'])\n",
      "Graphs Key:dict_keys(['pred', 'loss', 'true'])\n",
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pred': array([array([ 0,  1, 96]), array([ 0,  1, 96, 88]),\n",
       "        array([58, 59, 60, 62, 66,  5,  3,  2,  4,  6, 57,  7, 19]),\n",
       "        array([58, 59, 60, 62, 66,  5,  3,  2,  4,  6, 57,  7, 19]),\n",
       "        array([58, 59, 60, 62, 66,  5,  3,  2,  4,  6, 57,  7, 19]),\n",
       "        array([58, 59, 60, 62, 66,  5,  3,  2,  4,  6, 57,  7, 19]),\n",
       "        array([58, 59, 60, 62, 66,  5,  3,  2,  4,  6, 57,  7, 19]),\n",
       "        array([58, 59, 60, 62, 66,  5,  3,  2,  4,  6, 57,  7, 19]),\n",
       "        array([11, 21, 29, 61, 63, 64, 65, 67, 71,  8, 81, 34, 35, 85, 88, 36]),\n",
       "        array([21, 20, 63, 64, 65, 67, 71, 81, 34, 85, 88,  9, 27, 28]),\n",
       "        array([ 30,  38,  10,  12,  93, 102, 104,  23,  97,  39,  72,  82]),\n",
       "        array([11, 21, 29, 20, 63, 64, 65, 67, 71,  8, 81, 34, 35, 85, 88, 36, 27,\n",
       "        28]),\n",
       "        array([ 30,  38,  10,  12,  93, 102, 104,  23,  97,  39,  72,  82]),\n",
       "        array([ 63,  68,  70,  26,  22,  80,  13,  91,  92,  37,  14,  99, 100]),\n",
       "        array([ 63,  68,  70,  26,  22,  80,  13,  91,  92,  37,  14,  99, 100]),\n",
       "        array([ 15,  17,  25,  32,  33,  42,  74,  75, 106,  31,  40,  41,  83,\n",
       "         84,  94,  98, 103, 105]),\n",
       "        array([ 16,  25,  32,  33,  42,  74,  75, 106,  24,  31,  40,  41,  18,\n",
       "         83,  84,  94,  98, 103, 105]),\n",
       "        array([ 15,  17,  25,  32,  33,  42,  74,  75, 106,  31,  83,  84,  94,\n",
       "         98, 103, 105]),\n",
       "        array([ 16,  25,  32,  33,  42,  74,  75, 106,  24,  31,  40,  41,  18,\n",
       "         83,  84,  94,  98, 103, 105]),\n",
       "        array([58, 59, 60, 62, 66,  5,  3,  2,  4,  6, 57,  7, 19]),\n",
       "        array([20, 61, 64, 65, 79, 34, 85,  9, 27, 28]),\n",
       "        array([11, 21, 29, 61, 63, 64, 67, 71,  8, 81, 35, 88, 36]),\n",
       "        array([ 63,  68,  70,  26,  22,  80,  13,  91,  92,  37,  14,  99, 100]),\n",
       "        array([ 30,  38,  10,  12,  93, 102, 104,  23,  97,  39,  72,  82]),\n",
       "        array([ 15,  16,  32,  33,  42,  74,  75,  24,  31,  40,  41,  18,  73,\n",
       "         83,  84,  94,  98, 103]),\n",
       "        array([ 15,  16,  17,  25,  32,  33,  42,  74,  75, 106,  31,  18,  83,\n",
       "         84,  94,  98, 103, 105]),\n",
       "        array([ 68,  70,  26,  22,  80,  13,  91,  92,  37,  14,  99, 100]),\n",
       "        array([11, 20, 61, 64, 65, 69,  8, 79, 34, 85,  9, 27, 28]),\n",
       "        array([11, 20, 61, 64, 65, 69,  8, 79, 34, 85,  9, 27, 28]),\n",
       "        array([11, 21, 29, 63, 67, 71,  8, 81, 35, 87, 88, 36]),\n",
       "        array([ 30,  38,  10,  12,  93, 102, 104,  23,  97,  39,  72,  82]),\n",
       "        array([ 15,  16,  17,  25,  75,  24,  31,  40,  41,  18,  73,  83,  84,\n",
       "         98, 103]),\n",
       "        array([ 15,  17,  25,  32,  33,  42,  74,  75, 106,  18,  83,  84,  94,\n",
       "         98, 103, 105]),\n",
       "        array([ 15,  17,  25,  32,  33,  42,  74,  75, 106,  18,  83,  84,  94,\n",
       "         98, 103, 105]),\n",
       "        array([11, 20, 61, 64, 65, 69,  8, 79, 34, 85,  9, 27, 28]),\n",
       "        array([11, 21, 29, 63, 67, 71,  8, 81, 35, 88, 36]),\n",
       "        array([11, 21, 29, 63, 67, 71,  8, 81, 35, 88, 36]),\n",
       "        array([ 68,  70,  26,  22,  80,  13,  91,  92,  37,  14,  99, 100]),\n",
       "        array([ 30,  38,  10,  12,  93, 102, 104,  23,  97,  39,  72,  82]),\n",
       "        array([ 30,  38,  10,  12,  93, 102, 104,  23,  97,  39,  72,  82]),\n",
       "        array([15, 16, 24, 31, 40, 41, 18, 73, 98]),\n",
       "        array([15, 16, 17, 24, 31, 40, 41, 18, 73, 98]),\n",
       "        array([ 15,  16,  17,  25,  32,  33,  42,  74,  75, 106,  24,  18,  83,\n",
       "         84,  94,  98, 103, 105]),\n",
       "        array([43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]),\n",
       "        array([43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]),\n",
       "        array([43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]),\n",
       "        array([43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]),\n",
       "        array([43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]),\n",
       "        array([43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]),\n",
       "        array([43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]),\n",
       "        array([43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]),\n",
       "        array([43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]),\n",
       "        array([43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]),\n",
       "        array([43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]),\n",
       "        array([43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]),\n",
       "        array([43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]),\n",
       "        array([43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]),\n",
       "        array([58, 59, 60, 62, 66,  5,  3,  2,  4,  6, 57,  7, 19]),\n",
       "        array([58, 59, 60, 62, 66,  5,  3,  2,  4,  6, 57,  7, 19]),\n",
       "        array([58, 59, 60, 62, 66,  5,  3,  2,  4,  6, 57,  7, 19]),\n",
       "        array([58, 59, 60, 62, 66,  5,  3,  2,  4,  6, 57,  7, 19]),\n",
       "        array([11, 21, 20, 61, 64, 65, 69,  8, 79, 34, 85,  9, 27, 28]),\n",
       "        array([58, 59, 60, 62, 66,  5,  3,  2,  4,  6, 57,  7, 19]),\n",
       "        array([11, 21, 29, 63, 67, 71,  8, 81, 13, 35, 88, 36, 37, 14,  9]),\n",
       "        array([11, 20, 61, 64, 65, 69,  8, 79, 34, 85,  9, 27, 28]),\n",
       "        array([11, 20, 61, 64, 65, 69,  8, 79, 34, 85,  9, 27, 28]),\n",
       "        array([58, 59, 60, 62, 66,  5,  3,  2,  4,  6, 57,  7, 19]),\n",
       "        array([11, 21, 29, 63, 67, 71,  8, 81, 35, 88, 36,  9]),\n",
       "        array([ 68,  70,  26,  22,  80,  13,  91,  92,  37,  14,  99, 100]),\n",
       "        array([20, 61, 64, 65, 69, 79, 34, 85, 27, 28]),\n",
       "        array([ 68,  70,  26,  22,  80,  13,  91,  92,  37,  14,  99, 100]),\n",
       "        array([11, 21, 29, 63, 67, 71,  8, 81, 35, 88, 36]),\n",
       "        array([ 30,  38,  10,  12,  93, 102, 104,  23,  97,  39,  72,  82]),\n",
       "        array([ 24,  31,  40,  41,  73, 103]),\n",
       "        array([ 15,  16,  17,  25,  32,  33,  42,  74,  75, 106,  24,  31,  18,\n",
       "         83,  84,  94,  98, 103, 105]),\n",
       "        array([ 15,  16,  17,  25,  32,  33,  42,  74,  75, 106,  31,  18,  83,\n",
       "         84,  94,  98, 103, 105]),\n",
       "        array([76, 86, 87]), array([77, 78, 89, 90]),\n",
       "        array([77, 78, 89, 90]),\n",
       "        array([61, 64, 65, 69, 79, 34, 85, 27, 28]),\n",
       "        array([ 68,  70,  26,  22,  80,  13,  91,  92,  37,  14,  99, 100]),\n",
       "        array([11, 21, 29, 63, 67, 71,  8, 81, 35, 88, 36,  9]),\n",
       "        array([ 30,  38,  10,  12,  93, 102, 104,  23,  97,  39,  72,  82]),\n",
       "        array([ 15,  16,  17,  25,  32,  33,  42,  74,  75, 106,  24,  31,  18,\n",
       "         83,  84,  94,  98, 103, 105]),\n",
       "        array([ 15,  16,  17,  25,  32,  33,  42,  74,  75, 106,  24,  31,  18,\n",
       "         83,  84,  94,  98, 103, 105]),\n",
       "        array([11, 20, 61, 64, 65, 69,  8, 79, 34, 85,  9, 27, 28]),\n",
       "        array([71, 76, 86, 87]), array([96, 71, 76, 86, 87]),\n",
       "        array([11, 21, 29, 63, 67, 71,  8, 81, 35, 88, 36,  9]),\n",
       "        array([77, 78, 89, 90, 95]), array([77, 78, 89, 90, 95]),\n",
       "        array([ 68,  70,  26,  22,  80,  13,  91,  92,  37,  14,  99, 100]),\n",
       "        array([ 68,  70,  26,  22,  80,  13,  91,  92,  37,  14,  99, 100]),\n",
       "        array([ 30,  38,  10,  12,  93, 102, 104,  23,  97,  39,  72,  82]),\n",
       "        array([ 15,  16,  17,  25,  32,  33,  42,  74,  75, 106,  24,  40,  41,\n",
       "         18,  83,  84,  94,  98, 103, 105]),\n",
       "        array([101,  89,  90,  95]), array([ 0,  1, 96, 88]),\n",
       "        array([ 30,  38,  10,  12,  93, 102, 104,  23,  97,  39,  72,  82]),\n",
       "        array([ 15,  16,  17,  25,  32,  33,  42,  74,  75, 106,  24,  31,  18,\n",
       "         83,  84,  94,  98, 103, 105]),\n",
       "        array([ 68,  70,  26,  22,  80,  13,  91,  92,  37,  14,  99, 100]),\n",
       "        array([ 68,  70,  26,  22,  80,  13,  91,  92,  37,  14,  99, 100]),\n",
       "        array([101,  95]),\n",
       "        array([ 30,  38,  10,  12,  93, 102, 104,  23,  97,  39,  72,  82]),\n",
       "        array([ 15,  16,  17,  25,  32,  33,  42,  74,  75, 106,  24,  31,  18,\n",
       "         73,  83,  84,  94,  98, 103, 105]),\n",
       "        array([ 30,  38,  10,  12,  93, 102, 104,  23,  97,  39,  72,  82]),\n",
       "        array([ 15,  16,  17,  25,  32,  33,  42,  74,  75, 106,  18,  83,  84,\n",
       "         94,  98, 103, 105]),\n",
       "        array([ 15,  16,  17,  25,  32,  33,  42,  74,  75, 106,  18,  83,  84,\n",
       "         94,  98, 103, 105])], dtype=object),\n",
       " 'loss': array([list([0, 1, 8, 9, 10, 11, 12, 18, 21, 23, 29, 30, 35, 36, 38, 39, 40, 49, 60, 61, 64, 66, 67, 70, 71, 72, 76, 81, 82, 85, 86, 87, 88, 93, 94, 95, 96, 97, 100, 101, 102, 104]),\n",
       "        list([0, 1, 8, 10, 11, 12, 21, 22, 23, 25, 29, 30, 35, 36, 37, 38, 39, 46, 53, 59, 60, 61, 63, 64, 65, 69, 71, 72, 76, 79, 80, 81, 82, 85, 86, 87, 88, 89, 93, 95, 96, 97, 100, 101, 102, 104, 106]),\n",
       "        list([2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 15, 18, 19, 20, 22, 23, 27, 28, 32, 34, 37, 43, 49, 54, 57, 58, 59, 60, 62, 63, 65, 66, 67, 69, 76, 77, 78, 79, 86, 87, 91, 92, 97, 99]),\n",
       "        list([2, 3, 4, 5, 6, 7, 14, 16, 19, 20, 22, 23, 26, 27, 28, 34, 45, 49, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 69, 73, 75, 76, 77, 78, 79, 80, 85, 86, 87, 88, 91, 92, 99, 105, 106]),\n",
       "        list([1, 2, 3, 4, 5, 6, 7, 9, 13, 14, 19, 20, 27, 28, 29, 34, 47, 49, 52, 53, 57, 58, 59, 60, 62, 63, 65, 66, 67, 69, 73, 76, 77, 78, 79, 85, 86, 87, 91, 92, 94, 96, 99]),\n",
       "        list([2, 3, 4, 5, 6, 7, 17, 19, 20, 27, 28, 34, 37, 38, 43, 51, 53, 55, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 69, 76, 77, 78, 79, 83, 86, 87, 91, 92, 94, 95, 99, 101]),\n",
       "        list([2, 3, 4, 5, 6, 7, 12, 15, 19, 20, 27, 28, 31, 33, 34, 42, 50, 55, 56, 57, 58, 59, 60, 62, 63, 65, 66, 67, 69, 73, 76, 77, 78, 79, 81, 85, 86, 87, 91, 92, 96, 98, 99, 102]),\n",
       "        list([1, 2, 3, 4, 5, 6, 7, 18, 19, 20, 27, 28, 31, 34, 39, 50, 52, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 73, 76, 77, 78, 79, 86, 87, 91, 92, 93, 96, 98, 99, 104]),\n",
       "        list([7, 8, 9, 10, 11, 17, 20, 21, 24, 27, 28, 29, 33, 34, 35, 36, 38, 41, 45, 53, 59, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 77, 79, 81, 82, 85, 86, 87, 88, 92, 95, 96, 97, 98, 99, 100, 106]),\n",
       "        list([7, 8, 9, 11, 13, 20, 21, 23, 24, 25, 26, 27, 28, 29, 31, 34, 35, 36, 37, 45, 59, 61, 63, 64, 65, 67, 69, 70, 71, 73, 79, 81, 85, 86, 87, 88, 89, 90, 95, 96, 97, 98, 99, 100, 104]),\n",
       "        list([0, 1, 2, 9, 10, 12, 16, 18, 19, 20, 23, 24, 30, 31, 32, 33, 37, 38, 39, 40, 42, 46, 47, 50, 65, 70, 72, 73, 74, 75, 82, 83, 84, 90, 93, 94, 97, 98, 100, 101, 102, 103, 104]),\n",
       "        list([7, 8, 9, 11, 12, 20, 21, 24, 27, 28, 29, 30, 32, 33, 34, 35, 36, 47, 51, 61, 63, 64, 65, 67, 68, 69, 70, 71, 75, 76, 79, 81, 84, 85, 86, 87, 88, 95, 96, 97, 98, 99, 100, 101]),\n",
       "        list([0, 1, 7, 10, 12, 13, 14, 16, 18, 19, 23, 24, 28, 30, 31, 32, 33, 38, 39, 40, 42, 43, 55, 56, 66, 72, 74, 75, 77, 81, 82, 83, 84, 87, 89, 93, 94, 97, 98, 101, 102, 103, 104]),\n",
       "        list([2, 8, 13, 14, 22, 24, 26, 31, 34, 35, 36, 37, 48, 61, 62, 63, 64, 65, 67, 68, 70, 71, 73, 75, 77, 78, 80, 81, 82, 85, 86, 87, 88, 89, 90, 91, 92, 93, 97, 99, 100, 103]),\n",
       "        list([11, 13, 14, 19, 22, 24, 26, 31, 34, 35, 36, 37, 45, 55, 61, 63, 64, 65, 67, 68, 70, 71, 74, 77, 78, 80, 81, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 99, 100, 103]),\n",
       "        list([7, 10, 12, 15, 16, 17, 18, 20, 21, 23, 24, 25, 28, 30, 31, 32, 33, 35, 36, 38, 40, 41, 42, 44, 47, 51, 61, 66, 73, 74, 75, 80, 83, 84, 93, 94, 97, 98, 102, 103, 104, 105, 106]),\n",
       "        list([1, 2, 6, 10, 12, 15, 16, 17, 18, 21, 23, 24, 25, 30, 31, 32, 33, 34, 36, 37, 39, 40, 41, 42, 54, 71, 73, 74, 75, 80, 83, 84, 90, 91, 94, 97, 98, 102, 103, 104, 105, 106]),\n",
       "        list([10, 11, 12, 15, 16, 17, 18, 20, 21, 23, 24, 25, 28, 30, 31, 32, 33, 34, 38, 40, 41, 42, 48, 52, 56, 62, 73, 74, 75, 76, 82, 83, 84, 90, 94, 97, 98, 102, 103, 104, 105, 106]),\n",
       "        list([10, 12, 15, 16, 17, 18, 22, 23, 24, 25, 27, 30, 31, 32, 33, 37, 38, 39, 40, 41, 42, 46, 69, 70, 73, 74, 75, 82, 83, 84, 90, 92, 94, 97, 98, 101, 102, 103, 104, 105, 106]),\n",
       "        list([0, 1, 2, 3, 4, 5, 6, 7, 10, 12, 19, 20, 23, 25, 26, 27, 28, 33, 34, 50, 53, 56, 57, 58, 59, 60, 62, 63, 65, 66, 67, 69, 72, 75, 76, 77, 78, 79, 85, 86, 87, 90, 91, 92, 99, 100, 102]),\n",
       "        list([2, 5, 8, 9, 11, 13, 16, 17, 20, 21, 25, 26, 27, 28, 29, 34, 35, 36, 47, 58, 61, 63, 64, 65, 67, 69, 71, 77, 78, 79, 81, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 99]),\n",
       "        list([0, 4, 8, 9, 11, 16, 19, 20, 21, 22, 25, 27, 28, 29, 33, 34, 35, 36, 37, 39, 43, 48, 61, 63, 64, 65, 67, 68, 69, 71, 74, 79, 80, 81, 82, 85, 86, 87, 88, 89, 94, 95, 96, 97, 99, 100]),\n",
       "        list([3, 5, 8, 10, 13, 14, 17, 22, 24, 26, 30, 32, 34, 36, 37, 50, 51, 61, 63, 64, 65, 67, 68, 70, 71, 73, 77, 78, 80, 81, 85, 86, 87, 88, 89, 90, 91, 92, 96, 99, 100]),\n",
       "        list([0, 1, 9, 10, 12, 15, 16, 18, 23, 24, 26, 27, 30, 31, 32, 33, 38, 39, 42, 45, 46, 49, 51, 58, 63, 72, 74, 75, 79, 82, 83, 84, 86, 91, 93, 94, 96, 97, 98, 101, 102, 103, 104]),\n",
       "        list([5, 10, 12, 15, 16, 17, 18, 19, 21, 23, 24, 25, 30, 31, 32, 33, 36, 37, 39, 40, 41, 42, 46, 59, 66, 73, 74, 75, 80, 83, 84, 85, 90, 94, 96, 97, 98, 102, 103, 104, 105, 106]),\n",
       "        list([0, 4, 6, 10, 12, 15, 16, 17, 18, 20, 21, 23, 24, 25, 29, 30, 31, 32, 33, 37, 39, 40, 41, 42, 43, 50, 56, 62, 73, 74, 75, 76, 83, 84, 90, 94, 97, 98, 102, 103, 104, 105, 106]),\n",
       "        list([5, 6, 13, 14, 22, 26, 29, 34, 35, 36, 37, 42, 47, 49, 57, 58, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 75, 77, 78, 80, 81, 83, 85, 86, 87, 88, 91, 92, 95, 96, 99, 100]),\n",
       "        list([2, 3, 4, 8, 9, 11, 14, 16, 20, 21, 27, 28, 29, 34, 35, 36, 39, 41, 53, 60, 61, 63, 64, 65, 67, 68, 69, 71, 77, 78, 79, 81, 84, 85, 86, 87, 88, 89, 90, 95, 96, 101, 103, 106]),\n",
       "        list([4, 8, 9, 11, 15, 19, 20, 21, 27, 28, 29, 34, 35, 36, 41, 42, 45, 49, 59, 61, 63, 64, 65, 67, 69, 70, 71, 72, 76, 77, 78, 79, 80, 81, 82, 85, 86, 87, 88, 89, 90, 95, 96, 103]),\n",
       "        list([8, 9, 10, 11, 12, 17, 18, 19, 20, 21, 22, 27, 28, 29, 31, 34, 35, 36, 37, 48, 51, 61, 63, 64, 65, 67, 68, 69, 71, 72, 73, 77, 79, 81, 85, 86, 87, 88, 92, 96, 98, 99, 100, 101, 102]),\n",
       "        list([0, 1, 10, 12, 15, 16, 18, 23, 24, 25, 30, 31, 32, 33, 38, 39, 42, 51, 52, 53, 62, 65, 66, 70, 72, 73, 74, 75, 82, 83, 84, 89, 93, 94, 96, 97, 98, 101, 102, 103, 104, 106]),\n",
       "        list([10, 12, 14, 15, 16, 17, 18, 23, 24, 25, 30, 31, 32, 33, 35, 39, 40, 41, 42, 44, 52, 54, 60, 63, 65, 67, 72, 73, 74, 75, 81, 83, 84, 89, 94, 97, 98, 102, 103, 104, 105, 106]),\n",
       "        list([4, 8, 10, 12, 15, 16, 17, 18, 23, 24, 25, 29, 30, 31, 32, 33, 39, 40, 41, 42, 46, 49, 54, 62, 63, 68, 70, 73, 74, 75, 76, 83, 84, 86, 90, 91, 94, 97, 98, 99, 102, 103, 104, 105, 106]),\n",
       "        list([4, 9, 10, 12, 15, 16, 17, 18, 23, 24, 25, 28, 30, 31, 32, 33, 39, 40, 41, 42, 45, 51, 54, 62, 64, 73, 74, 75, 77, 81, 82, 83, 84, 94, 97, 98, 99, 100, 102, 103, 104, 105, 106]),\n",
       "        list([4, 6, 8, 9, 10, 11, 15, 17, 18, 20, 21, 27, 28, 29, 34, 35, 36, 38, 54, 61, 63, 64, 65, 67, 69, 70, 71, 72, 77, 78, 79, 81, 84, 85, 86, 87, 88, 89, 90, 91, 93, 95, 96, 101, 104]),\n",
       "        list([4, 7, 8, 9, 11, 15, 18, 20, 21, 24, 25, 26, 27, 28, 29, 32, 34, 35, 36, 37, 47, 52, 61, 63, 64, 65, 66, 67, 68, 69, 71, 73, 79, 81, 82, 85, 86, 87, 88, 91, 92, 96, 99, 100, 104]),\n",
       "        list([2, 6, 7, 8, 9, 11, 20, 21, 22, 27, 28, 29, 32, 33, 34, 35, 36, 37, 43, 44, 45, 48, 56, 61, 63, 64, 65, 67, 68, 69, 71, 72, 73, 79, 81, 85, 86, 87, 88, 92, 96, 98, 99, 100, 104]),\n",
       "        list([5, 6, 8, 13, 14, 21, 22, 26, 29, 34, 35, 36, 37, 44, 47, 52, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 74, 77, 80, 81, 85, 86, 87, 88, 91, 92, 95, 96, 98, 99, 100]),\n",
       "        list([0, 1, 10, 12, 15, 16, 18, 23, 24, 27, 30, 31, 32, 33, 38, 39, 42, 44, 50, 52, 53, 55, 63, 72, 74, 75, 77, 78, 82, 83, 84, 87, 91, 93, 94, 96, 97, 98, 101, 102, 103, 104]),\n",
       "        list([0, 1, 2, 3, 7, 9, 10, 12, 16, 18, 22, 23, 24, 30, 31, 32, 33, 35, 36, 38, 39, 42, 44, 48, 59, 66, 68, 72, 74, 75, 81, 82, 83, 84, 88, 89, 93, 94, 96, 97, 98, 99, 101, 102, 103, 104]),\n",
       "        list([1, 10, 12, 15, 16, 17, 18, 20, 23, 24, 25, 27, 29, 30, 31, 32, 33, 36, 37, 39, 40, 41, 42, 47, 57, 58, 68, 69, 71, 73, 74, 75, 81, 82, 83, 84, 94, 96, 97, 98, 102, 103, 104, 105, 106]),\n",
       "        list([3, 5, 10, 11, 12, 15, 16, 17, 18, 23, 24, 25, 27, 29, 30, 31, 32, 33, 37, 39, 40, 41, 42, 46, 56, 57, 59, 68, 72, 73, 74, 75, 77, 83, 84, 94, 96, 97, 98, 102, 103, 104, 105, 106]),\n",
       "        list([1, 9, 10, 12, 15, 16, 17, 18, 23, 24, 25, 30, 31, 32, 33, 34, 35, 39, 40, 41, 42, 43, 46, 57, 68, 71, 73, 74, 75, 79, 82, 83, 84, 85, 91, 94, 97, 98, 101, 102, 103, 104, 105, 106]),\n",
       "        list([13, 15, 16, 17, 18, 25, 31, 32, 33, 34, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 60, 64, 72, 74, 75, 76, 78, 83, 84, 85, 92, 94, 95, 96, 98, 103, 104, 105, 106]),\n",
       "        list([5, 6, 15, 16, 17, 20, 25, 28, 32, 33, 35, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 67, 68, 74, 75, 82, 83, 84, 85, 94, 98, 99, 102, 105, 106]),\n",
       "        list([2, 12, 13, 15, 16, 17, 19, 20, 25, 28, 32, 33, 37, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 74, 75, 83, 84, 94, 95, 98, 99, 103, 105, 106]),\n",
       "        list([3, 7, 15, 16, 17, 25, 29, 32, 33, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 61, 66, 74, 75, 83, 84, 91, 92, 94, 97, 98, 101, 105, 106]),\n",
       "        list([1, 6, 13, 15, 16, 17, 19, 25, 32, 33, 36, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 65, 74, 75, 77, 83, 84, 86, 91, 94, 97, 98, 99, 105, 106]),\n",
       "        list([1, 3, 4, 5, 15, 16, 17, 24, 25, 26, 27, 32, 33, 35, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 70, 71, 74, 75, 78, 79, 83, 84, 89, 94, 98, 99, 105, 106]),\n",
       "        list([5, 15, 16, 17, 22, 25, 32, 33, 37, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 62, 74, 75, 82, 83, 84, 87, 91, 94, 95, 96, 98, 104, 105, 106]),\n",
       "        list([3, 15, 16, 17, 19, 23, 25, 31, 32, 33, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 61, 68, 69, 72, 74, 75, 82, 83, 84, 92, 93, 94, 98, 105, 106]),\n",
       "        list([6, 10, 12, 15, 16, 17, 24, 25, 28, 29, 30, 32, 33, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 65, 74, 75, 83, 84, 92, 94, 96, 98, 101, 105, 106]),\n",
       "        list([5, 9, 10, 15, 16, 17, 19, 22, 25, 32, 33, 35, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 66, 68, 70, 71, 74, 75, 83, 84, 86, 91, 94, 98, 105, 106]),\n",
       "        list([11, 13, 14, 15, 16, 17, 25, 31, 32, 33, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 63, 70, 74, 75, 76, 78, 83, 84, 86, 89, 93, 94, 95, 96, 97, 98, 101, 105, 106]),\n",
       "        list([2, 8, 15, 16, 17, 20, 24, 25, 32, 33, 38, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 62, 67, 72, 73, 74, 75, 81, 83, 84, 92, 94, 98, 101, 104, 105, 106]),\n",
       "        list([3, 15, 16, 17, 21, 24, 25, 30, 32, 33, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 61, 65, 66, 68, 71, 74, 75, 76, 83, 84, 92, 94, 98, 104, 105, 106]),\n",
       "        list([8, 13, 15, 16, 17, 20, 25, 32, 33, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 62, 66, 67, 74, 75, 79, 83, 84, 94, 95, 98, 102, 105, 106]),\n",
       "        list([2, 3, 4, 5, 6, 7, 12, 16, 18, 19, 20, 22, 27, 28, 29, 34, 39, 41, 53, 54, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 69, 72, 73, 75, 76, 77, 78, 79, 81, 86, 87, 88, 91, 92, 99]),\n",
       "        list([0, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14, 15, 19, 20, 25, 27, 28, 34, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 69, 73, 76, 77, 78, 79, 82, 86, 87, 88, 91, 92, 93, 95, 99, 101]),\n",
       "        list([2, 3, 4, 5, 6, 7, 9, 11, 17, 19, 20, 25, 26, 27, 28, 29, 34, 41, 43, 49, 50, 57, 58, 59, 60, 62, 63, 65, 66, 67, 69, 76, 77, 78, 79, 86, 87, 91, 92, 93, 99, 102]),\n",
       "        list([2, 3, 4, 5, 6, 7, 11, 16, 19, 20, 27, 28, 34, 40, 51, 53, 55, 57, 58, 59, 60, 62, 63, 65, 66, 67, 69, 76, 77, 78, 79, 81, 86, 87, 91, 92, 97, 98, 99, 103, 104, 105]),\n",
       "        list([8, 9, 10, 11, 13, 14, 20, 21, 22, 23, 27, 28, 29, 31, 34, 35, 36, 39, 49, 50, 56, 61, 63, 64, 65, 66, 67, 69, 70, 71, 75, 77, 79, 81, 85, 87, 88, 89, 90, 91, 94, 95]),\n",
       "        list([2, 3, 4, 5, 6, 7, 19, 20, 21, 27, 28, 34, 43, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 69, 70, 74, 75, 76, 77, 78, 79, 81, 86, 87, 91, 92, 99, 100, 102, 104, 105, 106]),\n",
       "        list([1, 6, 8, 9, 11, 12, 13, 14, 20, 21, 22, 24, 25, 26, 27, 29, 34, 35, 36, 37, 45, 48, 55, 61, 62, 63, 65, 67, 68, 70, 71, 76, 80, 81, 85, 86, 87, 88, 89, 91, 92, 99, 100, 103]),\n",
       "        list([1, 3, 6, 8, 9, 11, 13, 14, 17, 20, 21, 22, 25, 27, 28, 29, 34, 35, 36, 44, 45, 48, 53, 59, 61, 64, 65, 67, 69, 71, 73, 79, 81, 85, 87, 88, 89, 90, 94, 95, 96, 101, 102, 104]),\n",
       "        list([2, 4, 8, 9, 11, 13, 15, 19, 20, 21, 22, 23, 25, 27, 28, 29, 34, 35, 36, 53, 58, 61, 63, 64, 65, 67, 69, 71, 77, 78, 79, 81, 85, 86, 87, 88, 89, 90, 93, 95, 105, 106]),\n",
       "        list([2, 3, 4, 5, 6, 7, 13, 14, 15, 19, 20, 21, 22, 24, 27, 28, 34, 42, 43, 44, 47, 57, 58, 59, 60, 62, 63, 65, 66, 67, 69, 74, 76, 77, 78, 79, 82, 86, 87, 90, 91, 92, 97, 99, 101, 102, 105]),\n",
       "        list([3, 8, 9, 11, 13, 14, 20, 21, 22, 26, 29, 31, 34, 35, 36, 37, 39, 43, 49, 54, 61, 63, 65, 66, 67, 68, 70, 71, 79, 80, 81, 85, 86, 87, 88, 89, 91, 92, 99, 100]),\n",
       "        list([8, 11, 13, 14, 21, 22, 26, 29, 34, 35, 36, 37, 41, 44, 47, 53, 58, 59, 61, 63, 65, 67, 68, 70, 71, 73, 74, 79, 80, 81, 82, 85, 86, 87, 88, 91, 92, 95, 96, 99, 100, 102]),\n",
       "        list([3, 8, 9, 11, 20, 21, 27, 28, 29, 30, 34, 35, 36, 43, 48, 51, 52, 55, 60, 61, 63, 64, 65, 67, 69, 71, 72, 77, 78, 79, 81, 85, 86, 87, 88, 89, 90, 95, 96, 97, 102, 103]),\n",
       "        list([3, 8, 12, 13, 14, 15, 22, 24, 26, 29, 34, 35, 36, 37, 41, 47, 49, 53, 54, 60, 61, 63, 64, 65, 66, 67, 68, 70, 71, 77, 80, 81, 85, 86, 87, 88, 91, 92, 95, 96, 99, 100]),\n",
       "        list([8, 9, 11, 16, 20, 21, 24, 27, 28, 29, 31, 34, 35, 36, 37, 46, 50, 54, 55, 58, 61, 63, 64, 65, 67, 68, 69, 71, 79, 81, 85, 86, 87, 88, 91, 92, 94, 96, 98, 99, 100, 103]),\n",
       "        list([0, 1, 6, 9, 10, 12, 13, 16, 18, 20, 23, 24, 27, 30, 31, 32, 33, 38, 39, 41, 42, 66, 71, 72, 74, 75, 76, 80, 81, 82, 83, 84, 86, 93, 94, 96, 97, 98, 100, 101, 102, 103, 104, 106]),\n",
       "        list([4, 10, 12, 13, 15, 16, 17, 18, 20, 22, 23, 24, 25, 27, 30, 31, 32, 33, 36, 38, 39, 40, 41, 42, 45, 70, 73, 74, 75, 78, 83, 84, 91, 92, 94, 97, 98, 100, 102, 103, 104, 105, 106]),\n",
       "        list([0, 2, 5, 9, 10, 12, 13, 15, 16, 17, 18, 21, 23, 24, 25, 28, 29, 30, 31, 32, 33, 39, 40, 41, 42, 43, 64, 69, 73, 74, 75, 81, 83, 84, 85, 87, 94, 97, 98, 101, 102, 103, 104, 105, 106]),\n",
       "        list([10, 12, 14, 15, 16, 17, 18, 22, 23, 24, 25, 29, 30, 31, 32, 33, 39, 40, 41, 42, 43, 44, 45, 49, 51, 61, 65, 67, 71, 73, 74, 75, 76, 78, 81, 83, 84, 86, 94, 97, 98, 102, 103, 104, 105, 106]),\n",
       "        list([0, 1, 2, 5, 8, 9, 13, 14, 20, 21, 23, 26, 27, 28, 29, 32, 34, 35, 36, 37, 44, 50, 55, 59, 63, 64, 65, 67, 68, 69, 70, 71, 76, 80, 85, 86, 87, 88, 91, 92, 95, 96, 99, 100]),\n",
       "        list([0, 3, 6, 9, 13, 14, 20, 22, 24, 26, 27, 28, 30, 34, 37, 51, 55, 56, 57, 58, 61, 63, 64, 65, 67, 69, 70, 71, 72, 77, 78, 79, 80, 81, 82, 83, 85, 86, 88, 89, 90, 91, 92, 95, 101, 105]),\n",
       "        list([0, 1, 6, 8, 9, 11, 12, 13, 14, 20, 22, 26, 27, 28, 34, 36, 37, 38, 48, 53, 57, 58, 60, 61, 63, 64, 65, 67, 69, 70, 71, 76, 77, 78, 79, 81, 85, 87, 88, 89, 90, 91, 92, 95, 99, 100, 101]),\n",
       "        list([0, 8, 9, 11, 20, 21, 25, 27, 28, 29, 33, 34, 35, 36, 43, 45, 47, 52, 61, 62, 63, 64, 65, 67, 69, 71, 75, 77, 78, 79, 81, 85, 86, 87, 88, 89, 90, 92, 95, 96, 99, 105]),\n",
       "        list([4, 7, 8, 13, 14, 17, 21, 22, 26, 28, 29, 34, 35, 36, 37, 41, 55, 61, 63, 64, 65, 67, 68, 69, 70, 71, 77, 80, 81, 85, 86, 87, 88, 91, 92, 94, 96, 98, 99, 100, 105]),\n",
       "        list([1, 4, 6, 8, 9, 11, 13, 18, 20, 21, 22, 25, 27, 28, 29, 34, 35, 36, 37, 41, 43, 52, 54, 58, 61, 63, 64, 65, 67, 69, 71, 72, 77, 78, 79, 81, 82, 83, 85, 86, 87, 88, 95, 96, 101, 104]),\n",
       "        list([0, 1, 5, 7, 10, 12, 16, 18, 23, 24, 29, 30, 31, 32, 33, 38, 39, 42, 45, 52, 53, 58, 62, 66, 70, 72, 74, 75, 79, 80, 82, 83, 84, 87, 92, 93, 94, 96, 97, 98, 100, 101, 102, 103, 104, 106]),\n",
       "        list([8, 10, 12, 15, 16, 17, 18, 20, 23, 24, 25, 30, 31, 32, 33, 35, 37, 39, 40, 41, 42, 44, 47, 49, 56, 63, 66, 70, 73, 74, 75, 83, 84, 89, 92, 94, 97, 98, 102, 103, 104, 105, 106]),\n",
       "        list([7, 10, 12, 15, 16, 17, 18, 23, 24, 25, 30, 31, 32, 33, 35, 39, 40, 41, 42, 49, 50, 60, 66, 73, 74, 75, 78, 83, 84, 91, 94, 97, 98, 101, 102, 103, 104, 105, 106]),\n",
       "        list([0, 4, 6, 8, 9, 11, 14, 17, 20, 21, 27, 28, 29, 31, 32, 34, 35, 36, 44, 46, 61, 63, 64, 65, 67, 69, 71, 75, 77, 78, 79, 81, 83, 85, 86, 87, 88, 89, 90, 92, 95, 96]),\n",
       "        list([0, 1, 2, 5, 8, 9, 11, 20, 21, 25, 27, 28, 29, 34, 35, 36, 37, 43, 45, 50, 51, 52, 54, 58, 59, 61, 63, 65, 66, 67, 68, 69, 71, 76, 77, 78, 79, 80, 81, 84, 85, 86, 87, 88, 91, 92, 95, 96, 99, 100]),\n",
       "        list([0, 1, 6, 8, 9, 11, 16, 17, 19, 20, 21, 27, 28, 29, 30, 34, 35, 36, 37, 48, 52, 61, 63, 64, 65, 67, 68, 69, 71, 75, 76, 77, 79, 80, 81, 83, 85, 86, 87, 88, 91, 92, 96, 99, 100, 101, 102]),\n",
       "        list([8, 11, 13, 14, 21, 22, 25, 26, 29, 32, 34, 35, 36, 37, 43, 48, 49, 58, 61, 63, 64, 67, 68, 69, 70, 71, 73, 74, 80, 81, 83, 85, 86, 87, 88, 90, 91, 92, 93, 96, 99, 100]),\n",
       "        list([0, 8, 9, 13, 14, 19, 20, 22, 25, 26, 27, 28, 29, 30, 32, 34, 36, 37, 39, 44, 45, 48, 51, 56, 57, 60, 61, 62, 63, 64, 65, 67, 69, 70, 71, 77, 78, 79, 81, 85, 88, 89, 90, 91, 95, 100, 101]),\n",
       "        list([6, 8, 9, 12, 13, 14, 16, 20, 22, 26, 27, 28, 29, 32, 33, 34, 36, 37, 54, 61, 63, 64, 65, 66, 67, 69, 70, 71, 77, 78, 79, 81, 82, 85, 88, 89, 90, 91, 93, 95, 98, 100, 101]),\n",
       "        list([8, 13, 14, 16, 21, 22, 24, 26, 29, 31, 34, 35, 36, 37, 38, 40, 41, 56, 61, 63, 64, 65, 67, 68, 70, 71, 72, 76, 77, 80, 81, 82, 85, 86, 87, 88, 91, 92, 95, 96, 97, 99, 100, 104]),\n",
       "        list([8, 12, 13, 14, 17, 19, 21, 22, 26, 29, 34, 35, 36, 37, 39, 48, 54, 57, 61, 63, 64, 65, 67, 68, 70, 71, 73, 74, 80, 81, 84, 85, 86, 87, 88, 91, 92, 96, 99, 100]),\n",
       "        list([0, 1, 10, 12, 16, 18, 21, 22, 23, 24, 25, 30, 31, 32, 33, 34, 38, 39, 40, 42, 47, 58, 68, 70, 72, 74, 75, 79, 80, 82, 83, 84, 89, 92, 93, 94, 96, 97, 98, 101, 102, 103, 104]),\n",
       "        list([1, 10, 12, 13, 15, 16, 17, 18, 23, 24, 25, 26, 30, 31, 32, 33, 34, 36, 37, 39, 40, 41, 42, 44, 58, 64, 65, 73, 74, 75, 83, 84, 88, 92, 94, 97, 98, 102, 103, 104, 105, 106]),\n",
       "        list([0, 4, 6, 8, 9, 11, 13, 14, 15, 18, 20, 21, 22, 26, 27, 28, 29, 34, 35, 36, 52, 54, 56, 59, 61, 64, 65, 69, 71, 77, 78, 79, 81, 84, 85, 88, 89, 90, 95, 96, 97, 101]),\n",
       "        list([0, 1, 5, 8, 9, 11, 17, 20, 21, 22, 23, 27, 28, 29, 30, 31, 34, 35, 36, 37, 39, 47, 59, 61, 64, 67, 69, 71, 76, 79, 81, 83, 84, 85, 86, 87, 88, 90, 95, 96, 100, 101]),\n",
       "        list([0, 1, 7, 10, 12, 13, 16, 17, 18, 23, 24, 30, 31, 32, 33, 38, 39, 42, 43, 44, 45, 57, 63, 71, 72, 74, 75, 77, 82, 83, 84, 85, 86, 88, 93, 94, 95, 96, 97, 98, 101, 102, 103, 104]),\n",
       "        list([4, 10, 12, 13, 15, 16, 17, 18, 23, 24, 25, 28, 29, 30, 31, 32, 33, 34, 39, 40, 41, 42, 45, 46, 56, 64, 65, 66, 71, 72, 73, 74, 75, 76, 83, 84, 87, 94, 97, 98, 102, 103, 104, 105, 106]),\n",
       "        list([6, 8, 11, 12, 13, 14, 21, 22, 26, 28, 29, 33, 34, 35, 36, 37, 56, 61, 63, 64, 65, 67, 68, 69, 70, 71, 72, 79, 80, 81, 84, 85, 86, 87, 88, 91, 92, 96, 99, 100]),\n",
       "        list([2, 3, 6, 8, 11, 13, 14, 18, 19, 21, 22, 25, 26, 29, 34, 35, 36, 37, 44, 46, 53, 55, 60, 61, 63, 65, 67, 68, 69, 70, 71, 80, 81, 84, 85, 86, 87, 88, 89, 91, 92, 96, 99, 100]),\n",
       "        list([0, 1, 6, 8, 9, 11, 12, 13, 14, 21, 22, 23, 26, 27, 28, 29, 33, 34, 35, 36, 37, 38, 43, 48, 49, 56, 57, 61, 64, 66, 68, 69, 70, 71, 75, 76, 77, 78, 81, 83, 85, 88, 89, 90, 95, 96, 101, 104]),\n",
       "        list([0, 1, 10, 12, 14, 15, 16, 18, 20, 21, 23, 24, 29, 30, 31, 32, 33, 36, 37, 38, 39, 42, 44, 50, 55, 57, 60, 65, 70, 72, 74, 75, 77, 82, 83, 84, 91, 93, 94, 96, 97, 98, 101, 102, 103, 104]),\n",
       "        list([0, 3, 4, 10, 12, 15, 16, 17, 18, 23, 24, 25, 26, 30, 31, 32, 33, 39, 40, 41, 42, 43, 46, 48, 50, 61, 73, 74, 75, 78, 81, 82, 83, 84, 85, 94, 97, 98, 102, 103, 104, 105, 106]),\n",
       "        list([0, 1, 2, 8, 10, 12, 16, 18, 20, 21, 23, 24, 26, 29, 30, 31, 32, 33, 38, 39, 42, 46, 62, 70, 72, 74, 75, 76, 82, 83, 84, 90, 92, 93, 94, 96, 97, 98, 101, 102, 103, 104]),\n",
       "        list([2, 5, 8, 9, 10, 12, 15, 16, 17, 18, 23, 24, 25, 27, 29, 30, 31, 32, 33, 37, 39, 40, 41, 42, 60, 64, 65, 68, 70, 73, 74, 75, 83, 84, 88, 94, 95, 97, 98, 102, 103, 104, 105, 106]),\n",
       "        list([10, 12, 13, 15, 16, 17, 18, 20, 23, 24, 25, 27, 30, 31, 32, 33, 39, 40, 41, 42, 43, 45, 49, 56, 65, 66, 73, 74, 75, 78, 83, 84, 92, 93, 94, 96, 97, 98, 102, 103, 104, 105, 106])],\n",
       "       dtype=object),\n",
       " 'true': [[0, 1, 76, 86, 87, 96],\n",
       "  [0, 1, 76, 86, 87, 96],\n",
       "  [2, 3, 4, 5, 6, 7, 19, 57, 58, 59, 60, 62, 66],\n",
       "  [2, 3, 4, 5, 6, 7, 19, 57, 58, 59, 60, 62, 66],\n",
       "  [2, 3, 4, 5, 6, 7, 19, 57, 58, 59, 60, 62, 66],\n",
       "  [2, 3, 4, 5, 6, 7, 19, 57, 58, 59, 60, 62, 66],\n",
       "  [2, 3, 4, 5, 6, 7, 19, 57, 58, 59, 60, 62, 66],\n",
       "  [2, 3, 4, 5, 6, 7, 19, 57, 58, 59, 60, 62, 66],\n",
       "  [8, 11, 21, 29, 35, 36, 63, 67, 71, 81, 88],\n",
       "  [9, 20, 27, 28, 34, 61, 64, 65, 69, 79, 85],\n",
       "  [10, 12, 23, 30, 38, 39, 72, 82, 93, 97, 102, 104],\n",
       "  [8, 11, 21, 29, 35, 36, 63, 67, 71, 81, 88],\n",
       "  [10, 12, 23, 30, 38, 39, 72, 82, 93, 97, 102, 104],\n",
       "  [13, 14, 22, 26, 37, 68, 70, 80, 91, 92, 99, 100],\n",
       "  [13, 14, 22, 26, 37, 68, 70, 80, 91, 92, 99, 100],\n",
       "  [15, 17, 25, 32, 33, 42, 74, 75, 83, 84, 94, 98, 103, 105, 106],\n",
       "  [16, 18, 24, 31, 40, 41, 73],\n",
       "  [15, 17, 25, 32, 33, 42, 74, 75, 83, 84, 94, 98, 103, 105, 106],\n",
       "  [16, 18, 24, 31, 40, 41, 73],\n",
       "  [2, 3, 4, 5, 6, 7, 19, 57, 58, 59, 60, 62, 66],\n",
       "  [9, 20, 27, 28, 34, 61, 64, 65, 69, 79, 85],\n",
       "  [8, 11, 21, 29, 35, 36, 63, 67, 71, 81, 88],\n",
       "  [13, 14, 22, 26, 37, 68, 70, 80, 91, 92, 99, 100],\n",
       "  [10, 12, 23, 30, 38, 39, 72, 82, 93, 97, 102, 104],\n",
       "  [16, 18, 24, 31, 40, 41, 73],\n",
       "  [15, 17, 25, 32, 33, 42, 74, 75, 83, 84, 94, 98, 103, 105, 106],\n",
       "  [13, 14, 22, 26, 37, 68, 70, 80, 91, 92, 99, 100],\n",
       "  [9, 20, 27, 28, 34, 61, 64, 65, 69, 79, 85],\n",
       "  [9, 20, 27, 28, 34, 61, 64, 65, 69, 79, 85],\n",
       "  [8, 11, 21, 29, 35, 36, 63, 67, 71, 81, 88],\n",
       "  [10, 12, 23, 30, 38, 39, 72, 82, 93, 97, 102, 104],\n",
       "  [16, 18, 24, 31, 40, 41, 73],\n",
       "  [15, 17, 25, 32, 33, 42, 74, 75, 83, 84, 94, 98, 103, 105, 106],\n",
       "  [15, 17, 25, 32, 33, 42, 74, 75, 83, 84, 94, 98, 103, 105, 106],\n",
       "  [9, 20, 27, 28, 34, 61, 64, 65, 69, 79, 85],\n",
       "  [8, 11, 21, 29, 35, 36, 63, 67, 71, 81, 88],\n",
       "  [8, 11, 21, 29, 35, 36, 63, 67, 71, 81, 88],\n",
       "  [13, 14, 22, 26, 37, 68, 70, 80, 91, 92, 99, 100],\n",
       "  [10, 12, 23, 30, 38, 39, 72, 82, 93, 97, 102, 104],\n",
       "  [10, 12, 23, 30, 38, 39, 72, 82, 93, 97, 102, 104],\n",
       "  [16, 18, 24, 31, 40, 41, 73],\n",
       "  [16, 18, 24, 31, 40, 41, 73],\n",
       "  [15, 17, 25, 32, 33, 42, 74, 75, 83, 84, 94, 98, 103, 105, 106],\n",
       "  [43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56],\n",
       "  [43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56],\n",
       "  [43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56],\n",
       "  [43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56],\n",
       "  [43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56],\n",
       "  [43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56],\n",
       "  [43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56],\n",
       "  [43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56],\n",
       "  [43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56],\n",
       "  [43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56],\n",
       "  [43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56],\n",
       "  [43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56],\n",
       "  [43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56],\n",
       "  [43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56],\n",
       "  [2, 3, 4, 5, 6, 7, 19, 57, 58, 59, 60, 62, 66],\n",
       "  [2, 3, 4, 5, 6, 7, 19, 57, 58, 59, 60, 62, 66],\n",
       "  [2, 3, 4, 5, 6, 7, 19, 57, 58, 59, 60, 62, 66],\n",
       "  [2, 3, 4, 5, 6, 7, 19, 57, 58, 59, 60, 62, 66],\n",
       "  [9, 20, 27, 28, 34, 61, 64, 65, 69, 79, 85],\n",
       "  [2, 3, 4, 5, 6, 7, 19, 57, 58, 59, 60, 62, 66],\n",
       "  [8, 11, 21, 29, 35, 36, 63, 67, 71, 81, 88],\n",
       "  [9, 20, 27, 28, 34, 61, 64, 65, 69, 79, 85],\n",
       "  [9, 20, 27, 28, 34, 61, 64, 65, 69, 79, 85],\n",
       "  [2, 3, 4, 5, 6, 7, 19, 57, 58, 59, 60, 62, 66],\n",
       "  [8, 11, 21, 29, 35, 36, 63, 67, 71, 81, 88],\n",
       "  [13, 14, 22, 26, 37, 68, 70, 80, 91, 92, 99, 100],\n",
       "  [9, 20, 27, 28, 34, 61, 64, 65, 69, 79, 85],\n",
       "  [13, 14, 22, 26, 37, 68, 70, 80, 91, 92, 99, 100],\n",
       "  [8, 11, 21, 29, 35, 36, 63, 67, 71, 81, 88],\n",
       "  [10, 12, 23, 30, 38, 39, 72, 82, 93, 97, 102, 104],\n",
       "  [16, 18, 24, 31, 40, 41, 73],\n",
       "  [15, 17, 25, 32, 33, 42, 74, 75, 83, 84, 94, 98, 103, 105, 106],\n",
       "  [15, 17, 25, 32, 33, 42, 74, 75, 83, 84, 94, 98, 103, 105, 106],\n",
       "  [0, 1, 76, 86, 87, 96],\n",
       "  [77, 78, 89, 90, 95, 101],\n",
       "  [77, 78, 89, 90, 95, 101],\n",
       "  [9, 20, 27, 28, 34, 61, 64, 65, 69, 79, 85],\n",
       "  [13, 14, 22, 26, 37, 68, 70, 80, 91, 92, 99, 100],\n",
       "  [8, 11, 21, 29, 35, 36, 63, 67, 71, 81, 88],\n",
       "  [10, 12, 23, 30, 38, 39, 72, 82, 93, 97, 102, 104],\n",
       "  [15, 17, 25, 32, 33, 42, 74, 75, 83, 84, 94, 98, 103, 105, 106],\n",
       "  [15, 17, 25, 32, 33, 42, 74, 75, 83, 84, 94, 98, 103, 105, 106],\n",
       "  [9, 20, 27, 28, 34, 61, 64, 65, 69, 79, 85],\n",
       "  [0, 1, 76, 86, 87, 96],\n",
       "  [0, 1, 76, 86, 87, 96],\n",
       "  [8, 11, 21, 29, 35, 36, 63, 67, 71, 81, 88],\n",
       "  [77, 78, 89, 90, 95, 101],\n",
       "  [77, 78, 89, 90, 95, 101],\n",
       "  [13, 14, 22, 26, 37, 68, 70, 80, 91, 92, 99, 100],\n",
       "  [13, 14, 22, 26, 37, 68, 70, 80, 91, 92, 99, 100],\n",
       "  [10, 12, 23, 30, 38, 39, 72, 82, 93, 97, 102, 104],\n",
       "  [15, 17, 25, 32, 33, 42, 74, 75, 83, 84, 94, 98, 103, 105, 106],\n",
       "  [77, 78, 89, 90, 95, 101],\n",
       "  [0, 1, 76, 86, 87, 96],\n",
       "  [10, 12, 23, 30, 38, 39, 72, 82, 93, 97, 102, 104],\n",
       "  [15, 17, 25, 32, 33, 42, 74, 75, 83, 84, 94, 98, 103, 105, 106],\n",
       "  [13, 14, 22, 26, 37, 68, 70, 80, 91, 92, 99, 100],\n",
       "  [13, 14, 22, 26, 37, 68, 70, 80, 91, 92, 99, 100],\n",
       "  [77, 78, 89, 90, 95, 101],\n",
       "  [10, 12, 23, 30, 38, 39, 72, 82, 93, 97, 102, 104],\n",
       "  [15, 17, 25, 32, 33, 42, 74, 75, 83, 84, 94, 98, 103, 105, 106],\n",
       "  [10, 12, 23, 30, 38, 39, 72, 82, 93, 97, 102, 104],\n",
       "  [15, 17, 25, 32, 33, 42, 74, 75, 83, 84, 94, 98, 103, 105, 106],\n",
       "  [15, 17, 25, 32, 33, 42, 74, 75, 83, 84, 94, 98, 103, 105, 106]]}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(samples[0].keys())\n",
    "print(\"Hit Key:{}\".format(samples[0]['hits'].keys()))\n",
    "print(\"Graphs Key:{}\".format(samples[0]['graphs'].keys()))\n",
    "print(type(samples[0]['hier']))\n",
    "samples[0]['graphs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations\n",
    "\n",
    "Choosing a sample to explore, one can see how the embedding differs from the raw features for graph creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAASH0lEQVR4nO3deXBd5XnH8d9jeRdgYSywwVCzF5dqsNGwDAMBlLKExZRJgbQ0NMnUZQqNTTMECNQ1lDSkTAPKhIYxhAINKaguYIxIWBxS3AGcyAsC6gVwSDCSYxEsgY03yU//uFdg6S6Sdd97z311v58ZjXTf9/icZ85Iv3n9nvecY+4uAEC8RiRdAACgMAQ5AESOIAeAyBHkABA5ghwAIjcyiYNOmjTJp02blsShASBay5cv/8Dda/u3JxLk06ZNU0tLSxKHBoBomdlvsrUztQIAkSPIASByBDkARI4gB4DIEeQAEDmCHAAiR5ADQOQSWUcOAJVi9dIXtfTRh/Xx7z/QvgdM0ulXfFnHnX5W0GMQ5ABQJE3/dLPee+O1Tz9//EGHnlvwA0kKGuZMrQBAEbxw/7/1CfFe3Tt3aOmjDwc9FkEOAEXw2vPP5Oz7+PcfBD0WQQ4AJbbvAZOC7o8gB4ASO/2KLwfdH0EOACUWetUKQQ4AkSPIAaAIqvefuFfthSDIAaAIrr734YzQrt5/oq6+N+zSQ4kbggCgaIoR2tkwIgeAyBHkABA5ghwAIkeQA0DkCHIAiBxBDgCRI8gBIHIEOQBEjiAHgMgR5AAQOYIcACJHkANA5AhyAIhckCA3sxozW2hma8xstZmdGmK/AICBhXqMbaOkn7n7F81stKTxgfYLABhAwUFuZvtJOkPSX0mSu++UtLPQ/QIABifE1MoRkjok/buZrTSz+82suv9GZjbbzFrMrKWjoyPAYQEAUpggHylppqQfuvsMSVsl3dh/I3df4O717l5fW1sb4LAAAClMkG+QtMHdl6U/L1Qq2AEAJVBwkLv7Rknvmdmx6aYGSf9X6H4BAIMTatXK30l6JL1iZb2krwTaLwBgAEGC3N1XSaoPsS8AwN7hzk4AiBxBDgCRI8gBIHIEOQBEjiAHgMgR5AAQOYIcACJHkANA5AhyAIgcQQ4AkSPIASByBDkARI4gB4DIEeQAEDmCHAAiR5ADQOQIcgCIXKhXvQFAH62trXr88ccz2uvr63XhhRcmUNHwxYgcQHC5QlySWlpa9PTTT5e4ouGNIAcQ3JIlS/L2L1++vESVVAaCHEBwXV1defvdvUSVVAaCHEBwEyZMyNtvZiWqpDIQ5ACCa2hoyNt/4oknlqiSykCQAwiurq5Ol156adY+Vq2Ex/JDAEVRV1enurq6pMuoCIzIASByBDkARI4gB4DIBQtyM6sys5Vmxi1bAFBCIUfkcyStDrg/AMAgBAlyM5sq6QJJ94fYHwBg8EKNyO+W9E1Ju3NtYGazzazFzFo6OjoCHRYAUHCQm9mFkja5e96n4Lj7Anevd/f62traQg8LAEgLMSI/TdLFZvaupEclnW1mPw6wXwDAIBQc5O5+k7tPdfdpkq6Q9HN3v7LgygAAg8I6cgCIXNBnrbj7LyT9IuQ+AQD5MSIHgMgR5AAQOYIcACJHkANA5AhyAIgcQQ4AkSPIASByBDkARI4gB4DIEeQAEDmCHAAiR5ADQOQIciAizeubdc7Cc1T3UJ3OWXiOmtc3J10SykDQpx8CKJ7m9c2a//J8be/ZLklq39qu+S/PlyRdcMQFCVaGpDEiByLRuKLx0xDvtb1nuxpXNCZUEcoFQQ5EYuPWjXvVjspBkAORmFw9ea/aUTkIciASc2bO0diqsX3axlaN1ZyZcxKqCOWCi51AJHovaDauaNTGrRs1uXqy5sycw4VOEORATC444gKCGxmYWgGAyBHkABA5ghwAIkeQA0DkCHIAiBxBDiSAh18hJJYfAiXGw68QGiNyoMR4+BVCKzjIzexQM3vRzFab2Ztmxv3CQB48/AqhhRiRd0v6hrsfJ+kUSdeY2fQA+wWGJR5+hdAKDnJ3b3f3FemfP5a0WtIhhe4XGK7OmHpGRhsPv0Ihgs6Rm9k0STMkLcvSN9vMWsyspaOjI+RhgWg0r2/WorcXZbTPOmoWFzoxZMGC3Mz2kfTfkua6+0f9+919gbvXu3t9bW1tqMMCUfnOsu9kXOiUpJc2vJRANRguggS5mY1SKsQfcffHQ+wTGG6a1zera2dX1j4udKIQIVatmKQfSVrt7t8rvCRgeMq3vJALnShEiBH5aZL+UtLZZrYq/fWFAPsFhpV8o24udKIQBd/Z6e7/K8kC1AIMS83rm9W4olEuz9pfM6aGC50oCLfoA0V0+6u367G1j+XsH1s1VjeedGMJK8JwRJADRdK8vjlviE+pnsI7NxEEQQ4UyR2/vCNnn8n03BefK2E1GM54aBZQBM3rm9W5ozNnP6tUEBJBDhTBrS/fmrefVSoIiSAHAmte36xtPdty9l9+7OXMiyMoghwILN/cuCTdcsotJaoElYIgBwIaaG68ZkxNCatBpSDIgYAGessPa8ZRDCw/RFBbV27SR8++q57OHaqqGaP9zp2m6hkHJl1WyeS7DZ+5cRQLI3IEs3XlJm1uWquezh2SpJ7OHdrctFZbV25KuLLSybWscMLoCcyNo2gIcgSzeeFaZTxOxKXNj61V+x2/rIhAnzNzjsZWje3TNrZqrG46+aaEKkIlYGoFQWxduUnqyd3f07lDnY+/JUnDeqqld+qkcUWjNm7dqMnVk7kNH0VHkCOIrsXvDLiN79qtj559d1gHuZQKc4IbpcTUCoLY/Un3oLbrnT8HEA5BjpKqqhmTdAnAsEOQIwgbVzXwNqNGaL9zpxW/GKDCEOQIoubio7L+NtnoVGNVzRjVXHr0sJ8fB5LAxU4E0RvQlXwzEJAUghzBVM84kOAGEsDUCgBEjiAHgMgR5AAQOYIcACJHkANA5AhyAIgcQQ4AkQuyjtzMzpPUKKlK0v3unv/tsxi21i3bqFcWvaMtH+7QPhPH6NRZR+qYk7O/bAFAGAWPyM2sStI9ks6XNF3Sl8xseqH7RXzWLduoFx9Zoy0fpp5wuOXDHXrxkTVatyz3688AFC7E1MpJkt529/XuvlPSo5JmBdgvIvPKonfUvXN3n7bunbv1yqKBn1UOYOhCTK0cIum9PT5vkHRygP2i3LU2SUtuk7o2SBOmasuHjZIsY7PeETqA4ggR5Jl/uZlvbpSZzZY0W5IOO+ywAIdFolqbpMVfl3ZtS33uek/7VH2gLT21GZvaCOmeq3/OnDlQJCGmVjZIOnSPz1MltfXfyN0XuHu9u9fX1mb+sSMyS277LMTTTq3+D420nRmbenq2hTlzoDhCBPmvJB1tZoeb2WhJV0h6KsB+Uc66NmQ0HTN+qc7a9x7tMzH1FiDL8tvFnDkQXsFTK+7ebWbXSnpWqeWHD7j7mwVXhvI2YarU9V5G8zFTfq1jrjtNUmo6JRvmzIGwgtwQ5O7PuPsx7n6ku387xD5R5hrmSaPG9W0bNS7VntY7Mu8vVzuAoeHOTgxN3WXSRd+XJhwqyVLfL/p+qj1t2vEHZPyzkaNH6NRZR5awUGD44w1BGLq6y/oE957WLduoNa9mXtScfPh+rFoBAiPIMXitTdJPb5C2fZj6PG6idP53s4Z5tpuDJGnD2k6tW7aRMAcCYmoFg9PaJC265rMQl1I/P/m3qb5+8l3QZNUKEBZBjsFZcpvUk7lGXLt3pfr6GTWmKueuWLUChEWQY3CyrBvP1fc/P1mjXTt6cm6ebX05gKHjTwqDM2HqoPrWLduoN17KuLG3D8+cOgdQAIIcg9MwT6oandk+YlSfteNLm9YNuCvWkQNhEeQYnLrLpFn3pFaq9BpVLY3ZV3p8tnTX8VJrk7Zv7R5wV6wjB8IiyDF4dZdJN/xamt8lXXqfpN3pVSyeul1/8deV5cGXfUw9toalh0BgrCPH0GR5+qF2bdMYfaQdmpD1nxx/xsH63J//YQmKAyoLI3IMTY5VLGfs9yOZ+i5TtCrpT74ynRAHioQROYYm19MPxy+VJL2y5Upt2V2rfSaO5WUSQJER5Biahnl93xC0h2PGL/000HXpfVLdaSUuDqgsFRXkT658X3c+u1Ztndt0cM04XX/usbpkxiFJlxWn3uerLLkt68j8U0tuy/lgLQBhVMwc+ZMr39c3/us1vd+5TS7p/c5tmvvYKt3y5OtJlxavusuk696Q6r+We5t8d4QCCKJigvzmJ15Xz+7MpXE/fvW3enLl+wlUNEy0NkkrHszdn++OUABBVEyQb92Z+9kfcx9bRZgP1dNzpd05zm2/NwYBKI6KCfKBzH1slabd2KwZtz1HqA9Wa5O0c2vu/n5vDAJQHBUT5DbI7TZ/skvXL3yNMB9Ia1P6Ts48CHGgJComyP/ilMMGve2uHtedz64tYjXDQLY7OwEkomKC/PZL/lhHH1g96O3bOgmpvAZcjTLY/wMBKFTFBLkkPf/3Z+q0IycOvKGkg2vGFbmayA20GqX+q6WpA0BlBbkkPfLXp+ruy0+QDTBgvP7cY0tTUKwa5qVWpfRnI1Lryi/8XulrAipURd3Z2av3bs7rF76mXT2Za8uvPOUw7vgcSJ87OzekRugN87jACSSgIoNc+izMb138pjZ/skuSVDNulOZf/EeE+GDVXUZwA2WgYoNcSoU5oQ0gdhU3Rw4Aw01BQW5md5rZGjNrNbMnzKwmVGEAgMEpdET+vKTj3b1O0jpJNxVeEgBgbxQU5O7+nLv3vjb9VUk86g4ASizkHPlXJf00V6eZzTazFjNr6ejoCHhYAKhsA65aMbMXJGV74eLN7r4ovc3NkrolPZJrP+6+QNICSaqvr89cvA0AGJIBg9zdP5+v38yuknShpAZ3J6ABoMQKWkduZudJukHS59z9kzAlAQD2RqFz5D+QtK+k581slZndG6AmAMBeKGhE7u5HhSoEADA03NkJAJEjyAEgcgQ5AESOIAeAyBHkABA5ghwAIkeQA0DkogvyrsWL9dbZDVp93HS9dXaDuhYvTrokAEhUVEHetXix2v9hnrrb2iR3dbe1qe36b2rNjJkEOoCKFVWQb7rrbvn27Rntvm2b2m76FmEOoCJFFeTdbW15Oru16a67S1cMAJSJqIJcVVV5u7vb20tUCACUj7iCvKcnb/fIKVNKVAgAlI+ognzkwQfn7T/wurklqgQAykdUQT5QUE+46KISVQIA5SOqIAcAZIoqyNu//c9JlwAAZSeqIPfOzpx9Nn58CSsBgPIRVZDnM+XW+UmXAACJiCrIq2pqsrbb+PFc6ARQsaIK8oNu/pZs1Kg+bTZqFKNxABVtZNIF7I3eUfemu+5Wd3u7Rk6ZogOvm8toHEBFiyrIpVSYE9wA8JmoplYAAJkIcgCIHEEOAJEjyAEgcgQ5AESOIAeAyJm7l/6gZh2SflPyA2c3SdIHSRdRZjgnfXE++uJ89FXK8/EH7l7bvzGRIC8nZtbi7vVJ11FOOCd9cT764nz0VQ7ng6kVAIgcQQ4AkSPIpQVJF1CGOCd9cT764nz0lfj5qPg5cgCIHSNyAIgcQQ4AkSPIJZnZfDN738xWpb++kHRNSTCz88xsrZm9bWY3Jl1P0szsXTN7Pf070ZJ0PUkwswfMbJOZvbFH20Qze97M3kp/3z/JGkspx/lIPD8I8s/c5e4npL+eSbqYUjOzKkn3SDpf0nRJXzKz6clWVRbOSv9OVOq66Qclndev7UZJS9z9aElL0p8rxYPKPB9SwvlBkKPXSZLedvf17r5T0qOSZiVcExLm7i9J+rBf8yxJD6V/fkjSJSUtKkE5zkfiCPLPXGtmren/OlXMfxX3cIik9/b4vCHdVslc0nNmttzMZiddTBk5yN3bJSn9/cCE6ykHieZHxQS5mb1gZm9k+Zol6YeSjpR0gqR2Sf+aaLHJsCxtlb429TR3n6nUdNM1ZnZG0gWhLCWeH9G9s3Oo3P3zg9nOzO6T9HSRyylHGyQdusfnqZLaEqqlLLh7W/r7JjN7Qqnpp5eSraos/M7Mprh7u5lNkbQp6YKS5O6/6/05qfyomBF5Pulfxl5/KumNXNsOY7+SdLSZHW5moyVdIemphGtKjJlVm9m+vT9LOkeV+XuRzVOSrkr/fJWkRQnWkrhyyI+KGZEP4F/M7ASlphLelfQ3yZZTeu7ebWbXSnpWUpWkB9z9zYTLStJBkp4wMyn1d/ITd/9ZsiWVnpn9p6QzJU0ysw2S/lHSHZKazOxrkn4r6c+Sq7C0cpyPM5POD27RB4DIMbUCAJEjyAEgcgQ5AESOIAeAyBHkABA5ghwAIkeQA0Dk/h8nttTqGj8zxQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_clusters(x,y,pid):\n",
    "    for g in np.unique(pid):\n",
    "        i = np.where(pid == g)\n",
    "        plt.scatter(x[i],y[i], label=g)\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "hits = samples[1]['hits']\n",
    "xyz = hits['xyz']\n",
    "emb = hits['emb']\n",
    "pid = hits['particle_id']\n",
    "\n",
    "# Original Hit coordinates\n",
    "plot_clusters(xyz[:,0], xyz[:,1], pid)\n",
    "\n",
    "# Metric Learning-based Emb coordinates\n",
    "plot_clusters(emb[:,0], emb[:,1], pid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Model\n",
    "\n",
    "To create this embedding, an MLP is trained to trainsform one hit into its embedded representation. Hinge loss over pairs of embedded hits supervises the MLP's learning process. To keep this tutorial succinct, the MLP embedding is included in the dataset, the MLP having been already trained.\n",
    "\n",
    "Clearly, the embedding will lead to superior clustering as compared with the raw *x,y,z* positions. \n",
    "However, this embedding incorporates information from only each hit individually. \n",
    "With a GNN, one can create embeddings which incorporate information from the hit's neighborhood. \n",
    "As we will see, this allows for superior embeddings and thus improved performance in clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph\n",
    "\n",
    "Once each point is embedded, the following steps occur in building a graph:\n",
    "\n",
    "1. Build a k-d tree with the embedded points.\n",
    "1. Query the neighborhood of every point, specifying either $k$, the number of neighbors, or $\\epsilon$, the size of the neighborhood around each point. In practice, $\\epsilon$-ball neighborhoods produce favorable results.\n",
    "1. Connect each point to its neighbors with an undirected graph.\n",
    "\n",
    "In keeping this tutorial succinct, these steps are already performed and the graph for each sample is included in the dataset.\n",
    "\n",
    "<img src=\"img/graph.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "The GNN model chosen is a simple message-passing architecture. One layer concatenates each node's features with an aggregation of the node's neighborhood, before applying a transformation via a fully-connected neural network layer.\n",
    "\n",
    "The output of the model is a set of node embeddings, where this new embedding has the same goal as in the graph building stage: according to some distance metric, node pairs whose hits belong to the same particle should be close, and otherwise they should be far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Weighting\n",
    "A multi-layer preceptron kernel determines edge weights of the graph at each layer.\n",
    "Here, each edge is represented by the features of its adjoining nodes.\n",
    "These features are passed through the MLP to produce an edge weight between 0 and 1.\n",
    "\n",
    "Consider the feature vectors of any two nodes, $x_i$ and $x_j$, which have an edge between them.\n",
    "Then their edge weight $w_{ij}$ is given as\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "w_{ij} &= \\text{sigmoid}(f([x_i, x_j])),\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $f$ is an MLP as defined in the graph weighting kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "- ReLU(Linear(nb_input*2, nb_hidden of e_feat))\n",
    "- -> ReLU(Linear(nb_hidden, nb_hidden of e_feat))\n",
    "- -> Sigmoid(Linear(nb_hidden, nb_output of e_feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_Kernel_DGL(nn.Module):\n",
    "    def __init__(self, nb_input, nb_hidden_gnn, nb_output=1, nb_layer=1):\n",
    "        super(MLP_Kernel_DGL, self).__init__()\n",
    "        \n",
    "        layers = [nn.Linear(nb_input*2, nb_hidden_gnn)]\n",
    "        for _ in range(nb_layer-1):\n",
    "            layers.append(nn.Linear(nb_hidden_gnn, nb_hidden_gnn))\n",
    "        layers.append(nn.Linear(nb_hidden_gnn, nb_output))\n",
    "        \n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.act2 = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, g):\n",
    "        g.apply_edges(self.mlp)\n",
    "        return g\n",
    "\n",
    "    def mlp(self, edges):\n",
    "        # Gather features from all relevant node pairs\n",
    "        src = edges.src['feat']\n",
    "        dst = edges.dst['feat']\n",
    "        e_feats = torch.cat((src,dst),dim=1)\n",
    "        \n",
    "        # Apply MLP layers to node pairs\n",
    "        for l in self.layers[:-1]:\n",
    "            e_feats = self.act1(l(e_feats))\n",
    "        \n",
    "        # Apply final output with sigmoid\n",
    "        e_feats = self.layers[-1](e_feats)\n",
    "        e_feats = self.act2(e_feats)\n",
    "        return {'e' : e_feats}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GNN Layer\n",
    "Each GNN layer first, if applicable, normalizes the incoming graph nodes, updates the graph weighting based on that layer's edge weight kernel, then applies graph convolution.\n",
    "\n",
    "Consider node $i$ at a given layer, and the neighborhood of $i$ given as $N_i$.\n",
    "Then the feature vector $x_i$ is updated to $x'_i$ in the following way.\n",
    "First, incoming messages to $i$ are weighted and aggregated:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "z_i = \\sum_{j \\in N_i} w_{ij} * x_{j}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Next, $x_i$ and $z_i$ are concatenated and transformed:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "x'_i = \\text{ReLU}(\\phi([x_i, z_i])),\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $\\phi$ is a learned affine transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arhictecture\n",
    "#### ReLU(Linear(2*input_dimn, nb_hidden of BachNorm(Edge_Weighting(node_feats))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete GNN layer, including normalization, graph weighting, and convolution\n",
    "class GNN_Layer(nn.Module):\n",
    "    def __init__(self, input_dim, nb_hidden_gnn, nb_hidden_kernel, apply_norm=True):\n",
    "        super(GNN_Layer, self).__init__()\n",
    "\n",
    "        self.edge_weighting = MLP_Kernel_DGL(input_dim, nb_hidden_kernel)\n",
    "        self.bn = nn.BatchNorm1d(input_dim,momentum=0.10) if apply_norm else None\n",
    "        self.fc = nn.Linear(2*input_dim, nb_hidden_gnn)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, g, features):\n",
    "        # maybe apply normalization\n",
    "        if self.bn is not None:\n",
    "            features = self.bn(features)\n",
    "        g.ndata['feat'] = features\n",
    "\n",
    "        # set edge weights for this layer\n",
    "        g = self.edge_weighting(g)\n",
    "        \n",
    "        # send weighted messages and apply graph convolution to nodes\n",
    "        g.update_all(message_func=dgl.function.u_mul_e('feat', 'e', 'msg'),\n",
    "                     reduce_func=dgl.function.sum('msg', 'agg_msg'))\n",
    "        \n",
    "        # concat and apply an affine transformation\n",
    "        node_feats = torch.cat((features, g.ndata['agg_msg']), dim=1)\n",
    "        emb = self.fc(node_feats)\n",
    "        emb = self.act(emb)\n",
    "        \n",
    "        return emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GNN\n",
    "The GNN consists of several layers as defined above. \n",
    "A final embedding layer takes the node features as output by the GNN layers, and applies an affine transformation to a low dimension space as defined by emb_dim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(nn.Module):\n",
    "    def __init__(self, nb_hidden_gnn, nb_layer, nb_hidden_kernel, input_dim, emb_dim=2):\n",
    "        super(GNN, self).__init__()\n",
    "\n",
    "        # Construct GNN Layers\n",
    "        gnn_layers = [GNN_Layer(input_dim, nb_hidden_gnn, nb_hidden_kernel, apply_norm=True)]\n",
    "        for _ in range(nb_layer-1):\n",
    "            gnn_layers.append(GNN_Layer(nb_hidden_gnn, nb_hidden_gnn, nb_hidden_kernel))\n",
    "        self.layers = nn.ModuleList(gnn_layers)\n",
    "\n",
    "        self.final_emb = nn.Linear(nb_hidden_gnn, emb_dim)\n",
    "\n",
    "    def forward(self, g):\n",
    "        emb = g.ndata.pop('feat')\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            emb = layer(g, emb)\n",
    "        emb = self.final_emb(emb)\n",
    "        return emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "## Dataset, Dataloader\n",
    "\n",
    "The TrackML_Dataset class is a PyTorch Dataset subclass, for use in a DataLoader class.\n",
    "The trackml_collate function should be used when instantiating the DataLoader class for minibatch training.\n",
    "\n",
    "Each sample will contain a graph (with features) used as input, and a graph with ground truth information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gnn_utils import TrackML_Dataset\n",
    "\n",
    "def trackml_collate(samples):\n",
    "    g_input = [s[0] for s in samples]\n",
    "    g_input = dgl.batch(g_input)\n",
    "\n",
    "    g_true = [s[1] for s in samples]\n",
    "    g_true = dgl.batch(g_true)\n",
    "\n",
    "    return g_input, g_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This collate function makes use of DGL's batch functionality, allowing computation over minibatches of variable-sized graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup for DataLoader and GNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# PARAMETERS\n",
    "batch_size = 4\n",
    "nb_hidden = 32\n",
    "nb_layers = 4\n",
    "learn_rate = 0.001\n",
    "\n",
    "dataset = TrackML_Dataset(samples)\n",
    "dataloader = DataLoader(dataset, \n",
    "                        batch_size=batch_size, \n",
    "                        collate_fn=trackml_collate,\n",
    "                        drop_last=True, \n",
    "                        shuffle=True,\n",
    "                        num_workers=0)\n",
    "\n",
    "net = GNN(nb_hidden_gnn=nb_hidden, nb_layer=nb_layers, nb_hidden_kernel=nb_hidden, input_dim=6)\n",
    "optim = torch.optim.Adamax(params=net.parameters(), lr=learn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adamax (\n",
       "Parameter Group 0\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.001\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN(\n",
      "  (layers): ModuleList(\n",
      "    (0): GNN_Layer(\n",
      "      (edge_weighting): MLP_Kernel_DGL(\n",
      "        (layers): ModuleList(\n",
      "          (0): Linear(in_features=12, out_features=32, bias=True)\n",
      "          (1): Linear(in_features=32, out_features=1, bias=True)\n",
      "        )\n",
      "        (act1): ReLU()\n",
      "        (act2): Sigmoid()\n",
      "      )\n",
      "      (bn): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (fc): Linear(in_features=12, out_features=32, bias=True)\n",
      "      (act): ReLU()\n",
      "    )\n",
      "    (1): GNN_Layer(\n",
      "      (edge_weighting): MLP_Kernel_DGL(\n",
      "        (layers): ModuleList(\n",
      "          (0): Linear(in_features=64, out_features=32, bias=True)\n",
      "          (1): Linear(in_features=32, out_features=1, bias=True)\n",
      "        )\n",
      "        (act1): ReLU()\n",
      "        (act2): Sigmoid()\n",
      "      )\n",
      "      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (fc): Linear(in_features=64, out_features=32, bias=True)\n",
      "      (act): ReLU()\n",
      "    )\n",
      "    (2): GNN_Layer(\n",
      "      (edge_weighting): MLP_Kernel_DGL(\n",
      "        (layers): ModuleList(\n",
      "          (0): Linear(in_features=64, out_features=32, bias=True)\n",
      "          (1): Linear(in_features=32, out_features=1, bias=True)\n",
      "        )\n",
      "        (act1): ReLU()\n",
      "        (act2): Sigmoid()\n",
      "      )\n",
      "      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (fc): Linear(in_features=64, out_features=32, bias=True)\n",
      "      (act): ReLU()\n",
      "    )\n",
      "    (3): GNN_Layer(\n",
      "      (edge_weighting): MLP_Kernel_DGL(\n",
      "        (layers): ModuleList(\n",
      "          (0): Linear(in_features=64, out_features=32, bias=True)\n",
      "          (1): Linear(in_features=32, out_features=1, bias=True)\n",
      "        )\n",
      "        (act1): ReLU()\n",
      "        (act2): Sigmoid()\n",
      "      )\n",
      "      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (fc): Linear(in_features=64, out_features=32, bias=True)\n",
      "      (act): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (final_emb): Linear(in_features=32, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss\n",
    "Hinge embedding loss produces embeddings which are amenable to clustering, since they only penalize false pairs when the distance between false pairs becomes small.\n",
    "The hinge loss is stated as:\n",
    "\n",
    "$\n",
    "        l = \\begin{cases}\n",
    "            x, & \\text{if}\\; y = 1,\\\\\n",
    "            \\max \\{0, \\Delta - x\\}, & \\text{if}\\; y = -1,\n",
    "        \\end{cases}\n",
    "$\n",
    "where $x$ is the prediction measuring similarity, and $y$ is the target $\\in \\{-1,1\\}$.\n",
    "\n",
    "Here a DGL edge function is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emb_for_loss(edges):\n",
    "    src = edges.src['emb']\n",
    "    dst = edges.dst['emb']\n",
    "    pred_dist = nn.functional.pairwise_distance(src, dst)\n",
    "    truth = edges.data['truth']\n",
    "    true_dist = truth*2 - 1\n",
    "    loss = nn.functional.hinge_embedding_loss(pred_dist, true_dist, reduction='none')\n",
    "    return {'loss' : loss, 'pred_dist' : pred_dist, 'true_dist' : true_dist}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "An accuracy proxy helps as a sanity check during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_dist_accuracy(pred, true):\n",
    "    pred = pred.round()\n",
    "    pred[pred!=0] = 1\n",
    "    pred = 1-pred\n",
    "    correct = pred==true\n",
    "    nb_correct = correct.sum()\n",
    "    nb_total = true.size(0)\n",
    "    score = float(nb_correct.item()) / nb_total\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "Train over the dataset for a few epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training on 100 samples\n",
      "  48  Loss: 0.220  Acc: 78.7\n",
      "  96  Loss: 0.177  Acc: 83.5\n",
      "\n",
      "Training on 100 samples\n",
      "  48  Loss: 0.086  Acc: 92.5\n",
      "  96  Loss: 0.082  Acc: 93.2\n",
      "\n",
      "Training on 100 samples\n",
      "  48  Loss: 0.062  Acc: 95.8\n",
      "  96  Loss: 0.066  Acc: 94.9\n",
      "\n",
      "Training on 100 samples\n",
      "  48  Loss: 0.057  Acc: 96.1\n",
      "  96  Loss: 0.058  Acc: 95.9\n",
      "\n",
      "Training on 100 samples\n",
      "  48  Loss: 0.058  Acc: 95.4\n",
      "  96  Loss: 0.059  Acc: 95.5\n",
      "\n",
      "Training on 100 samples\n",
      "  48  Loss: 0.050  Acc: 96.1\n",
      "  96  Loss: 0.054  Acc: 96.0\n",
      "\n",
      "Training on 100 samples\n",
      "  48  Loss: 0.052  Acc: 96.2\n",
      "  96  Loss: 0.057  Acc: 95.7\n",
      "\n",
      "Training on 100 samples\n",
      "  48  Loss: 0.050  Acc: 96.4\n",
      "  96  Loss: 0.051  Acc: 96.3\n",
      "\n",
      "Training on 100 samples\n",
      "  48  Loss: 0.049  Acc: 96.7\n",
      "  96  Loss: 0.050  Acc: 96.3\n",
      "\n",
      "Training on 100 samples\n",
      "  48  Loss: 0.051  Acc: 96.1\n",
      "  96  Loss: 0.052  Acc: 96.1\n"
     ]
    }
   ],
   "source": [
    "def train_one_epoch(net, batch_size, optimizer, train_loader):\n",
    "    net.train()\n",
    "\n",
    "    nb_batch = len(train_loader)\n",
    "    nb_train = nb_batch * batch_size\n",
    "    epoch_score = 0\n",
    "    epoch_loss  = 0\n",
    "\n",
    "    print(\"\\nTraining on {} samples\".format(nb_train))\n",
    "    for i, (g_input, g_true) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward the GNN model on the input graph and set the result to the augmented graph\n",
    "        g_true.ndata['emb'] = net(g_input)\n",
    "        \n",
    "        # compute loss function over the augmented graph\n",
    "        g_true.apply_edges(get_emb_for_loss)\n",
    "        loss = g_true.edata.pop('loss').mean()\n",
    "        score = score_dist_accuracy(g_true.edata.pop('pred_dist'), g_true.edata.pop('truth'))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_score += score * 100\n",
    "        epoch_loss  += loss.item()\n",
    "\n",
    "        nb_proc = (i+1) * batch_size\n",
    "        if (((i+1) % (nb_batch//2)) == 0):\n",
    "            print(\"  {:2d}  Loss: {:.3f}  Acc: {:2.1f}\".format(nb_proc, epoch_loss/(i+1), epoch_score/(i+1)))\n",
    "    return epoch_loss / nb_batch, epoch_score / nb_batch\n",
    "\n",
    "for i in range(10):\n",
    "    train_one_epoch(net, batch_size, optim, dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=1, collate_fn=trackml_collate)\n",
    "\n",
    "# Embed samples\n",
    "orig_xyz = []\n",
    "emb_metric = []\n",
    "emb_gnn = []\n",
    "pid = []\n",
    "weight = []\n",
    "net.eval()\n",
    "with torch.autograd.no_grad():\n",
    "    for i, (g_input, g_true) in enumerate(dataloader):\n",
    "        f = g_input.ndata['feat']\n",
    "        pid.append(g_input.ndata['pid'])\n",
    "        \n",
    "        ## Original XYZ (Shape = (-1, 3))\n",
    "        orig_xyz.append(g_input.ndata['feat'][:,:3])\n",
    "        \n",
    "        ## Metric Embeddings (Shape = (-1, 3))\n",
    "        emb_metric.append(g_input.ndata['feat'][:,3:])\n",
    "        weight.append(g_input.ndata['weight'])\n",
    "        \n",
    "        #GNN Embeddings (Shape = (-1, 2))\n",
    "        hits_emb = net(g_input)\n",
    "        emb_gnn.append(hits_emb.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([99, 2])"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hits_emb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, visualize the tracks in the original space, metric learning embedding, and GNN embedding.\n",
    "Not that the metric learning model was trained for many hours on GPU, while training the GNN in this notebook is quite limited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([107, 3])"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_xyz[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "j = 1\n",
    "to_plot = [orig_xyz[j], emb_metric[j], emb_gnn[j]]\n",
    "for emb in to_plot:\n",
    "    plot_clusters(emb[:,0], emb[:,1], pid[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "c = DBSCAN(eps=.24, min_samples=3)\n",
    "\n",
    "def get_clusters(embedding):\n",
    "    return c.fit_predict(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring\n",
    "The score of one predicted cluster is nonzero only if a large majority of its points belong to the same true cluster, and if the majority of the true cluster is contained within the predicted cluster.  A perfect clustering will thus lead to a score of 1, while a random clustering will almost certainly have a score of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score samples\n",
    "from gnn_utils import score_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrackML score: 0.88\n"
     ]
    }
   ],
   "source": [
    "### Get final cluster scores\n",
    "import pandas\n",
    "\n",
    "avg_score = 0.0\n",
    "nb_samples = 20\n",
    "for i in range(nb_samples):\n",
    "    # emb = samples[i]['hits']['emb']\n",
    "    # clusters = get_clusters(emb)\n",
    "    clusters = get_clusters(emb_gnn[i])\n",
    "    hit_ids = np.arange(len(clusters))\n",
    "    truth = pandas.DataFrame.from_dict({'particle_id':pid[i].numpy(),\n",
    "                                        'hit_id':hit_ids,\n",
    "                                        'weight':weight[i].numpy()})\n",
    "    submission = pandas.DataFrame.from_dict({'hit_id':hit_ids,\n",
    "                                             'track_id':clusters})\n",
    "    score = score_event(truth, submission)\n",
    "    avg_score += score\n",
    "print(\"TrackML score: {:.2f}\".format(avg_score / nb_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>particle_id</th>\n",
       "      <th>hit_id</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.801530e+17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.801530e+17</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.657135e+17</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.657135e+17</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.531271e+17</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>9.457772e+16</td>\n",
       "      <td>98</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>9.457772e+16</td>\n",
       "      <td>99</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>7.160772e+17</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>7.160772e+17</td>\n",
       "      <td>101</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>7.160772e+17</td>\n",
       "      <td>102</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      particle_id  hit_id    weight\n",
       "0    1.801530e+17       0  0.000015\n",
       "1    1.801530e+17       1  0.000013\n",
       "2    2.657135e+17       2  0.000007\n",
       "3    2.657135e+17       3  0.000007\n",
       "4    1.531271e+17       4  0.000005\n",
       "..            ...     ...       ...\n",
       "98   9.457772e+16      98  0.000014\n",
       "99   9.457772e+16      99  0.000012\n",
       "100  7.160772e+17     100  0.000014\n",
       "101  7.160772e+17     101  0.000011\n",
       "102  7.160772e+17     102  0.000013\n",
       "\n",
       "[103 rows x 3 columns]"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
